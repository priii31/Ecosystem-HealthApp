# -*- coding: utf-8 -*-
"""EcoApp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ef_Cd6TLuBAAM0xxNXRmr4n0lKkuPV0N
"""

# =============================
# Ecosystem Health Monitoring â€“ Final Stable Version (With About Page)
# =============================

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import io
import os
import time
from datetime import datetime
from fpdf import FPDF

import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# ----------------------------------------------------
# STREAMLIT PAGE CONFIG
# ----------------------------------------------------
st.set_page_config(page_title="Ecosystem Health Monitoring", layout="wide")
st.title("ðŸŒ¿ Ecosystem Health Monitoring Dashboard")

# ----------------------------------------------------
# FILE PATHS FOR MODELS
# ----------------------------------------------------
MODEL_PATH = "ecosystem_rf_model.pkl"
SCALER_PATH = "scaler.pkl"
LABEL_PATH = "label_encoder.pkl"

# ----------------------------------------------------
# REQUIRED COLUMNS
# ----------------------------------------------------
REQUIRED_COLS = [
    "Temperature", "Humidity", "AirQuality",
    "PWater_pH", "Soil_Moisture", "Light_Level"
]

def check_required_columns(df):
    return [c for c in REQUIRED_COLS if c not in df.columns]

def extract_hour(df):
    if "Timestamp" in df.columns:
        df["Timestamp"] = pd.to_datetime(df["Timestamp"], errors="ignore")
        df["Hour"] = df["Timestamp"].dt.hour.fillna(12).astype(int)
    else:
        df["Hour"] = 12
    return df

# ----------------------------------------------------
# LOAD SAVED MODEL COMPONENTS
# ----------------------------------------------------
@st.cache_resource
def load_components():
    model = joblib.load(MODEL_PATH) if os.path.exists(MODEL_PATH) else None
    scaler = joblib.load(SCALER_PATH) if os.path.exists(SCALER_PATH) else None
    encoder = joblib.load(LABEL_PATH) if os.path.exists(LABEL_PATH) else None
    return model, scaler, encoder

model, scaler, label_encoder = load_components()

# ----------------------------------------------------
# SIDEBAR NAVIGATION
# ----------------------------------------------------
page = st.sidebar.selectbox(
    "Navigate",
    [
        "Dashboard",
        "Predictions",
        "Train Model",
        "Analytics",
        "Report",
        "IoT Simulation",
        "About"
    ]
)

uploaded = st.sidebar.file_uploader("Upload Dataset (CSV)", type=["csv"])

# ====================================================
# 1. DASHBOARD PAGE
# ====================================================
if page == "Dashboard":
    st.header("Dashboard â€” Quick Overview")

    if uploaded is None:
        st.info("Upload CSV to continue.")
    else:
        try:
            df = pd.read_csv(uploaded)
        except:
            df = pd.read_csv(uploaded, encoding="latin1")

        df.columns = df.columns.str.strip()
        missing = check_required_columns(df)

        if missing:
            st.error(f"Missing columns: {missing}. Required: {REQUIRED_COLS}")
        else:
            df = extract_hour(df)

            st.subheader("Data Preview")
            st.dataframe(df.head())

            c1, c2, c3 = st.columns(3)
            c1.metric("Avg Temperature", round(df["Temperature"].mean(), 2))
            c2.metric("Avg Humidity", round(df["Humidity"].mean(), 2))
            c3.metric("Avg Air Quality", round(df["AirQuality"].mean(), 2))

            if model and scaler and label_encoder:
                X = df[REQUIRED_COLS + ["Hour"]].apply(pd.to_numeric, errors="coerce").fillna(0)
                X_scaled = scaler.transform(X)
                preds = model.predict(X_scaled)
                df["Predicted_Health"] = label_encoder.inverse_transform(preds)

                fig = px.pie(df, names="Predicted_Health", title="Health Distribution")
                st.plotly_chart(fig, use_container_width=True)

                classes = list(label_encoder.classes_)
                mapping = {cls: (i/(len(classes)-1) * 100) for i, cls in enumerate(classes)} if len(classes)>1 else {classes[0]: 100}

                df["Health_Score"] = df["Predicted_Health"].map(mapping)
                avg_score = round(df["Health_Score"].mean(), 2)

                gauge = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=avg_score,
                    number={'suffix': " /100"},
                    title={'text': "Average Ecosystem Health Score"},
                    gauge={
                        'axis': {'range': [0, 100]},
                        'bar': {'color': "darkgreen" if avg_score>70 else "gold" if avg_score>50 else "red"},
                        'steps': [
                            {'range': [0, 50], 'color': "lightcoral"},
                            {'range': [50, 75], 'color': "gold"},
                            {'range': [75, 100], 'color': "lightgreen"},
                        ],
                    },
                ))

                st.plotly_chart(gauge, use_container_width=True)

            else:
                st.warning("Model not found! Train model first.")

# ====================================================
# 2. PREDICTIONS PAGE
# ====================================================
elif page == "Predictions":
    st.header("Run Predictions")

    if uploaded is None:
        st.info("Upload CSV to continue.")
    else:
        df = pd.read_csv(uploaded)
        df = extract_hour(df)

        if not model:
            st.error("Model not loaded. Train model first.")
        else:
            X = df[REQUIRED_COLS + ["Hour"]].apply(pd.to_numeric, errors="coerce").fillna(0)
            X_scaled = scaler.transform(X)

            preds = model.predict(X_scaled)
            df["Predicted_Health"] = label_encoder.inverse_transform(preds)

            st.success("Predictions Completed!")
            st.dataframe(df.head())

            st.download_button("Download Predictions", df.to_csv(index=False), "predictions.csv")

# ====================================================
# 3. TRAIN MODEL PAGE
# ====================================================
elif page == "Train Model":
    st.header("Train New Model")

    train_file = st.file_uploader("Upload Training CSV", type=["csv"], key="train")

    if train_file:
        df = pd.read_csv(train_file)
        df = extract_hour(df)

        def create_label(row):
            pH = row["PWater_pH"]
            aq = row["AirQuality"]
            sm = row["Soil_Moisture"]

            if aq < 35 and 6.5 <= pH <= 7.8 and sm > 20:
                return "Healthy"
            elif 35 <= aq <= 55 or 10 <= sm <= 20:
                return "Moderate"
            else:
                return "Critical"

        df["Health_Label"] = df.apply(create_label, axis=1)

        st.dataframe(df.head())

        if st.button("Train Model"):
            X = df[REQUIRED_COLS + ["Hour"]]
            y = df["Health_Label"]

            encoder = LabelEncoder()
            y_enc = encoder.fit_transform(y)

            scaler_new = StandardScaler()
            X_scaled = scaler_new.fit_transform(X)

            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_enc, test_size=0.2)

            model_new = RandomForestClassifier(n_estimators=200)
            model_new.fit(X_train, y_train)

            preds = model_new.predict(X_test)
            acc = accuracy_score(y_test, preds)

            st.success(f"Model trained! Accuracy: {acc}")
            st.text(classification_report(y_test, preds, target_names=encoder.classes_))

            joblib.dump(model_new, MODEL_PATH)
            joblib.dump(scaler_new, SCALER_PATH)
            joblib.dump(encoder, LABEL_PATH)

            st.success("Model Saved Successfully!")

# ====================================================
# 4. ANALYTICS PAGE
# ====================================================
elif page == "Analytics":
    st.header("Interactive Analytics")

    if uploaded:
        df = pd.read_csv(uploaded)
        df = extract_hour(df)

        x = st.selectbox("X-axis", df.columns)
        y = st.selectbox("Y-axis", REQUIRED_COLS)

        fig = px.scatter(df, x=x, y=y, color="Hour")
        st.plotly_chart(fig, use_container_width=True)

        corr = df[REQUIRED_COLS].corr()
        fig2 = px.imshow(corr, text_auto=True, title="Correlation Heatmap")
        st.plotly_chart(fig2, use_container_width=True)

# ====================================================
# 5. PDF REPORT PAGE (FIXED)
# ====================================================
# -------------------------
# PDF REPORT PAGE (FIXED)
# -------------------------
elif page == "Report":
    st.header("Generate PDF Report")

    if uploaded:
        df = pd.read_csv(uploaded)
        df = extract_hour(df)

        if st.button("Generate PDF"):

            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", "B", 18)
            pdf.cell(0, 10, "Ecosystem Health Report", ln=True, align="C")

            pdf.set_font("Arial", size=12)
            pdf.ln(5)

            for col in REQUIRED_COLS:
                # protect against missing/NaN values
                try:
                    mean_val = df[col].mean()
                    pdf.cell(0, 7, f"{col}: Mean = {mean_val:.2f}", ln=True)
                except Exception:
                    pdf.cell(0, 7, f"{col}: Mean = N/A", ln=True)

            # Save heatmap to a temporary PNG file (FPDF needs a path)
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.heatmap(df[REQUIRED_COLS].corr(), annot=True, ax=ax)
            img_path = "temp_heatmap.png"
            fig.savefig(img_path, bbox_inches="tight", dpi=150)
            plt.close(fig)

            pdf.ln(10)
            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 7, "Correlation Heatmap:", ln=True)

            # Insert the image into the PDF using its path
            try:
                pdf.image(img_path, w=180)
            except Exception as e:
                pdf.set_font("Arial", size=11)
                pdf.cell(0, 6, f"Failed to attach heatmap: {e}", ln=True)

            # --- IMPORTANT FIX: get PDF bytes via dest='S' and place into BytesIO ---
            pdf_str = pdf.output(dest='S')            # returns a string representation
            pdf_bytes = pdf_str.encode('latin-1')     # encode to bytes for PDF (latin-1)
            buffer = io.BytesIO(pdf_bytes)
            buffer.seek(0)

            st.success("PDF Ready!")
            st.download_button(
                "Download Report",
                buffer,
                file_name="ecosystem_report.pdf",
                mime="application/pdf"
            )

            # cleanup temp image
            try:
                os.remove(img_path)
            except Exception:
                pass

# ====================================================
# 6. IOT SIMULATION
# ====================================================
elif page == "IoT Simulation":
    st.header("IoT Simulation â€” Live Sensor Data")

    if "sim_df" not in st.session_state:
        st.session_state.sim_df = pd.DataFrame(columns=["Timestamp"] + REQUIRED_COLS)

    start, stop = st.columns(2)
    if start.button("Start Simulation"):
        st.session_state.run = True
    if stop.button("Stop Simulation"):
        st.session_state.run = False

    freq = st.slider("Frequency (seconds)", 1, 10, 3)

    if st.session_state.get("run", False):
        row = {
            "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "Temperature": np.random.uniform(20, 32),
            "Humidity": np.random.uniform(40, 80),
            "AirQuality": np.random.uniform(20, 80),
            "PWater_pH": np.random.uniform(6.0, 8.0),
            "Soil_Moisture": np.random.uniform(10, 40),
            "Light_Level": np.random.randint(200, 1200)
        }

        st.session_state.sim_df.loc[len(st.session_state.sim_df)] = row
        st.dataframe(st.session_state.sim_df.tail(10))

        time.sleep(freq)
        st.rerun()

# ====================================================
# 7. ABOUT PAGE
# ====================================================
elif page == "About":
    st.header("â„¹ï¸ About This Project")

    st.markdown("""
    ### ðŸŒ¿ Ecosystem Health Monitoring System
    This Streamlit application analyzes environmental sensor data to assess the health of an ecosystem using
    **Machine Learning, Data Visualization, and Real-Time IoT Simulation**.

    ---

    ### ðŸ” Key Features:
    - ðŸ“Š **Dashboard**: Live ecosystem overview
    - ðŸ”® **Predictions**: ML-based health predictions
    - ðŸ§  **Model Training**: Train RandomForest model in-app
    - ðŸ“ˆ **Analytics**: Interactive graphs and heatmaps
    - ðŸ“„ **PDF Report Generator**
    - ðŸ“¡ **IoT Sensor Simulation** (real-time)

    ---

    ### ðŸ› ï¸ Technologies Used
    - Python
    - Streamlit
    - Scikit-Learn
    - Plotly
    - FPDF
    - NumPy & Pandas

    ---

    ### ðŸ‘¨â€ðŸ’» Developed By
    **Priyal Choudhary / BCA 5th Semester(TECNIA INSTITUTE OF ADVANCED STUDIES)**

    """)

    st.success("Thank you for using the Ecosystem Health Monitoring System! ðŸŒ±")